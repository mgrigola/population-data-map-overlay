{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "fileDir = 'C:/Users/m/Documents/GitHub/population-data-map-overlay/data/info_by_zipcode/'\n",
    "fileName = 'ACS_16_5YR_S1901_with_ann.csv'\n",
    "outFileName = 'income-data.json'\n",
    "\n",
    "#optionally specify a selection of column headers you want to keep\n",
    "columnKeys = ['GEO.id2','HC01_EST_VC01','HC01_EST_VC02','HC01_EST_VC03','HC01_EST_VC04','HC01_EST_VC05','HC01_EST_VC06','HC01_EST_VC07','HC01_EST_VC08','HC01_EST_VC09','HC01_EST_VC10','HC01_EST_VC11','HC01_EST_VC13','HC01_EST_VC15','HC01_EST_VC18']\n",
    "\n",
    "\n",
    "incomeByZipDf = pd.read_csv(fileDir+fileName,header=[0],skiprows=[1])\n",
    "if columnKeys:\n",
    "    incomeByZipDf = incomeByZipDf[columnKeys]\n",
    "\n",
    "#generate a dictionary structure to map to json format\n",
    "#use first column from input file (from columnKeys) as the key and everything else in another dictionary beneath that\n",
    "#  where key=column_name, value=cell_val\n",
    "jsonDict = {}\n",
    "for rowIdx, rowData in incomeByZipDf.iterrows():\n",
    "    zipId = str(rowData[columnKeys[0]]).rjust(5,'0')\n",
    "    jsonDict[zipId] = dict(zip(columnKeys[1:],rowData[1:]))  #oh this is snazzy! it creates the dict under each zip in 1 line\n",
    "\n",
    "#write to a json file. \n",
    "with open(fileDir+outFileName, 'w') as outFile:\n",
    "    try:\n",
    "        yourVarName\n",
    "    except NameError:\n",
    "        pass\n",
    "    else:\n",
    "        outFile.write('var '+yourVarName+'=\\n')\n",
    "    json.dump(jsonDict, outFile)\n",
    "    \n",
    "\n",
    "headerDf = pd.read_csv(fileDir+fileName,header=[0],nrows=1)\n",
    "if columnKeys:\n",
    "    headerDf = headerDf[columnKeys]\n",
    "headerDict = dict(zip(headerDf.columns[1:], headerDf.iloc[0].values[1:]))\n",
    "\n",
    "with open(fileDir+'descriptions_'+outFileName, 'w') as describeOutFile:\n",
    "    json.dump(headerDict, describeOutFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HC01_EST_VC02</th>\n",
       "      <th>HC01_EST_VC03</th>\n",
       "      <th>HC01_EST_VC04</th>\n",
       "      <th>HC01_EST_VC05</th>\n",
       "      <th>HC01_EST_VC06</th>\n",
       "      <th>HC01_EST_VC07</th>\n",
       "      <th>HC01_EST_VC08</th>\n",
       "      <th>HC01_EST_VC09</th>\n",
       "      <th>HC01_EST_VC10</th>\n",
       "      <th>HC01_EST_VC11</th>\n",
       "      <th>HC01_EST_VC13</th>\n",
       "      <th>HC01_EST_VC15</th>\n",
       "      <th>HC01_EST_VC18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>518</td>\n",
       "      <td>419</td>\n",
       "      <td>537</td>\n",
       "      <td>511</td>\n",
       "      <td>560</td>\n",
       "      <td>625</td>\n",
       "      <td>505</td>\n",
       "      <td>503</td>\n",
       "      <td>323</td>\n",
       "      <td>494</td>\n",
       "      <td>19534</td>\n",
       "      <td>25951</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2985</td>\n",
       "      <td>3287</td>\n",
       "      <td>1758</td>\n",
       "      <td>1758</td>\n",
       "      <td>1389</td>\n",
       "      <td>1110</td>\n",
       "      <td>1885</td>\n",
       "      <td>2313</td>\n",
       "      <td>6195</td>\n",
       "      <td>7391</td>\n",
       "      <td>2008</td>\n",
       "      <td>586</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HC01_EST_VC02 HC01_EST_VC03 HC01_EST_VC04 HC01_EST_VC05 HC01_EST_VC06  \\\n",
       "count          33120         33120         33120         33120         33120   \n",
       "unique           518           419           537           511           560   \n",
       "top              0.0           0.0           0.0           0.0           0.0   \n",
       "freq            2985          3287          1758          1758          1389   \n",
       "\n",
       "       HC01_EST_VC07 HC01_EST_VC08 HC01_EST_VC09 HC01_EST_VC10 HC01_EST_VC11  \\\n",
       "count          33120         33120         33120         33120         33120   \n",
       "unique           625           505           503           323           494   \n",
       "top              0.0           0.0           0.0           0.0           0.0   \n",
       "freq            1110          1885          2313          6195          7391   \n",
       "\n",
       "       HC01_EST_VC13 HC01_EST_VC15 HC01_EST_VC18  \n",
       "count          33120         33120         33120  \n",
       "unique         19534         25951           794  \n",
       "top                -             -             -  \n",
       "freq            2008           586           580  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomeByZipDf[columnKeys[2:]].describe()  #why is ity only giving me these 2 columns?!? I'm so confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherFile = fileDir+'descriptions.txt'\n",
    "with open(otherFile, 'w') as describeTxtFile:\n",
    "    describeTxtFile.write(str(headerDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherFile = fileDir+'descriptions2.txt'\n",
    "with open(otherFile, 'w') as describeTxtFile:\n",
    "    for key,val in headerDict.items():\n",
    "        describeTxtFile.write('{}: {}'.format(key,val) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below is copied from shp2gjson. maybe should make a module...\n",
    "# *my state to zip mapping is incomplete. some smaller zips don't have their state listed here. They'll end up blank in leaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads/returns the pandas dataframe containing a list of state + zipcode pairs, either from file or from census beauru\n",
    "# will 'cache' (locally save on disk) the result if read from census and use the local copy next time requested\n",
    "def get_state_zip_df():\n",
    "    saveFile = '../data/shapefiles-us_zips/zip_state_map.csv'\n",
    "    # try to read read pre-downloaded and massaged file (if run/'cached' before), else download and save\n",
    "    # feels sloppy\n",
    "    try:\n",
    "        stateZipDf = pd.read_csv(saveFile, dtype=str)\n",
    "    except FileNotFoundError:\n",
    "        zipCol = 'ZCTA5'\n",
    "        stateCol = 'STUSAB'\n",
    "        stateIdCol = 'STATE'\n",
    "        readType = {zipCol: str, stateCol: str}\n",
    "\n",
    "        zipSourceURL = 'https://www2.census.gov/geo/docs/maps-data/data/rel/zcta_place_rel_10.txt'\n",
    "        zipInfoDf = pd.read_csv(zipSourceURL, usecols=[zipCol, stateIdCol], dtype=readType)\n",
    "        zipInfoDf.drop_duplicates(inplace=True)  # not sure what this data means, but there are several rows per zip\n",
    "\n",
    "        stateSourceURL = 'https://www2.census.gov/geo/docs/reference/state.txt'\n",
    "        stateInfoDf = pd.read_csv(stateSourceURL, sep='|')\n",
    "\n",
    "        # pandas JOIN on state(FIPS ID)\n",
    "        stateZipDf = pd.merge(zipInfoDf, stateInfoDf, left_on=stateIdCol, right_on=stateIdCol)\n",
    "        stateZipDf = stateZipDf[[zipCol, stateCol]]\n",
    "        #stateZipDf[zipCol] = stateZipDf[zipCol].apply(lambda x: str(x).rjust(5, '0'))  # convert zip from int to 5 char str #passing dtype=str on read already accomplishes this\n",
    "\n",
    "        stateZipDf.to_csv(saveFile, index=False)  # save, don't print index column\n",
    "\n",
    "    return stateZipDf\n",
    "\n",
    "# pass the stateZipDf from get_state_zip_df()\n",
    "# zip2StateDict[zipCode] = [state_zip_code_is_in, maybe_more_than_1_state]\n",
    "# state2ZipDict[state][zipCode]=''\n",
    "def gen_state_zip_dict(stateZipDf):\n",
    "    zipCol = 'ZCTA5'\n",
    "    stateCol = 'STUSAB'\n",
    "\n",
    "    zip2StateDict = {}\n",
    "    state2ZipDict = {}\n",
    "    for row in stateZipDf.iterrows():\n",
    "        zipCode = row[1][zipCol]\n",
    "        stateStr = row[1][stateCol]\n",
    "\n",
    "        if zipCode in zip2StateDict:\n",
    "            # print(zipCode, stateStr)  # zip codes in more than 1 state. interesting\n",
    "            zip2StateDict[zipCode].append(stateStr)\n",
    "        else:\n",
    "            zip2StateDict[zipCode] = [stateStr]\n",
    "\n",
    "        if stateStr in state2ZipDict:\n",
    "            state2ZipDict[stateStr][zipCode] = True\n",
    "        else:\n",
    "            state2ZipDict[stateStr] = {zipCode: True}\n",
    "\n",
    "    return zip2StateDict, state2ZipDict\n",
    "\n",
    "def create_state_zip_income_files(inputFile, targetBase):\n",
    "    zipDf = get_state_zip_df()\n",
    "    zipDict, stateDict = gen_state_zip_dict(zipDf)\n",
    "\n",
    "    stateCnt = 0\n",
    "    for state in stateDict.keys():\n",
    "        print(stateCnt, ': ', state)\n",
    "        stateCnt += 1\n",
    "        sinkFile = targetFile+'_'+state+'.json'\n",
    "        # gdal doesn't know how to overwrite a file\n",
    "        if os.path.isfile(sinkFile):\n",
    "            os.remove(sinkFile)\n",
    "\n",
    "        with fiona.open(shapeFile+'.shp', 'r') as src:\n",
    "            meta = src.meta\n",
    "            meta['schema']['properties'] = {'zip': 'str'}\n",
    "            meta['driver'] = 'GeoJSON'\n",
    "            with fiona.open(sinkFile, 'w', **meta) as sink:\n",
    "                for rec in src:\n",
    "                    #only include zips in this state\n",
    "                    if rec['properties']['ZCTA5CE10'] not in stateDict[state]:\n",
    "                        continue\n",
    "\n",
    "                    # I don't like displaying all the quirks of zip boundaries (and may be more costly to render), but this block isn't necessary\n",
    "                    # not polygon means the multi-level/nested polygon thing. This removes those complicated compound shapes\n",
    "                    if rec['geometry']['type'] != 'Polygon':\n",
    "                        # simplify multipolygon to polygon:\n",
    "                        # if polygon has negative space, the first element is the outer bound, skip other/interior pieces\n",
    "                        # if polygon consists of multiple, separate pieces (like islands) we include all of those\n",
    "                        newCoords = [coordSet[0] for coordSet in rec['geometry']['coordinates']]\n",
    "                        rec['geometry']['coordinates'] = newCoords\n",
    "                        rec['geometry']['type'] = 'Polygon'\n",
    "\n",
    "                    rec['properties'] = {'zip': rec['properties']['ZCTA5CE10']}\n",
    "                    sink.write(rec)\n",
    "\n",
    "    return\n",
    "\n",
    "create_state_zip_income_files('../data/info_by_zipcode/ACS_16_5YR_S1901_with_ann.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileDir = 'C:/Users/m/Documents/GitHub/population-data-map-overlay/data/info_by_zipcode/'\n",
    "fileName = 'ACS_16_5YR_S1901_with_ann.csv'\n",
    "outFileName = 'income-data.json'\n",
    "\n",
    "#optionally specify a selection of column headers you want to keep\n",
    "columnKeys = ['GEO.id2','HC01_EST_VC01','HC01_EST_VC02','HC01_EST_VC03','HC01_EST_VC04','HC01_EST_VC05','HC01_EST_VC06','HC01_EST_VC07','HC01_EST_VC08','HC01_EST_VC09','HC01_EST_VC10','HC01_EST_VC11','HC01_EST_VC13','HC01_EST_VC15','HC01_EST_VC18']\n",
    "\n",
    "\n",
    "incomeByZipDf = pd.read_csv(fileDir+fileName,header=[0],skiprows=[1])\n",
    "if columnKeys:\n",
    "    incomeByZipDf = incomeByZipDf[columnKeys]\n",
    "\n",
    "#generate a dictionary structure to map to json format\n",
    "#use first column from input file (from columnKeys) as the key and everything else in another dictionary beneath that\n",
    "#  where key=column_name, value=cell_val\n",
    "jsonDict = {}\n",
    "for rowIdx, rowData in incomeByZipDf.iterrows():\n",
    "    zipId = str(rowData[columnKeys[0]]).rjust(5,'0')\n",
    "    jsonDict[zipId] = dict(zip(columnKeys[1:],rowData[1:]))  #oh this is snazzy! it creates the dict under each zip in 1 line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

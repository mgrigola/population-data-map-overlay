{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import fiona\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shapefile is source .shp file/dir (pass without the .shp)\n",
    "# recFiltFunc is a function to call on each element/record in shapefile to filter out unwanted elements (you might be able to filter by zip codes in some set/dict here but I forget)\n",
    "# boundingBox is the bounding box of shape elements to keep - at least one point in shape must be inside boundingBox. Pass None (default) to avoid this\n",
    "# dataProp is the property in the shapefile that we care about? (like 'ZCTA5CE10' = 'GEOID10' = [zipcode])\n",
    "# newDataProp is what we'll rename dataProp in the output (like 'ZCTA5CE10'->'zip')\n",
    "def translate_shapefile_bounding_box(shapeFile, recFiltFunc=None, propMap={}, boundingBox=None):\n",
    "    # clear the existing target file (this is necessary? seems like it shouldn't be)\n",
    "    if os.path.isfile(shapeFile+'.json'):\n",
    "        os.remove(shapeFile+'.json')\n",
    "\n",
    "    recList = []\n",
    "    idCnt = 0\n",
    "    with fiona.open(shapeFile+'.shp', 'r') as src:\n",
    "        meta = src.meta\n",
    "        #schemaDict = {'id': 'int'}\n",
    "        schemaDict = {}  # defines the format/datatype of properties element in output\n",
    "        for key,val in propMap.items():\n",
    "            schemaDict[val] = 'str'\n",
    "        meta['schema']['properties'] = schemaDict\n",
    "        meta['driver'] = 'GeoJSON'\n",
    "        with fiona.open(shapeFile+'.json', 'w', **meta) as sink:\n",
    "            for rec in filter(recFiltFunc, src):\n",
    "                if idCnt > 1000:\n",
    "                    break\n",
    "\n",
    "                # I don't like displaying all the quirks of zip boundaries (and may be more costly to render), but this block isn't necessary\n",
    "                # not polygon means the multi-level/nested polygon thing. This removes those complicated compound shapes\n",
    "                if rec['geometry']['type'] != 'Polygon':\n",
    "                    # simplify multipolygon to polygon:\n",
    "                    # if polygon has negative space, the first element is the outer bound, skip other/interior pieces\n",
    "                    # if polygon consists of multiple, separate pieces (like islands) we include all of those\n",
    "                    newCoords = [coordSet[0] for coordSet in rec['geometry']['coordinates']]\n",
    "                    rec['geometry']['coordinates'] = newCoords\n",
    "                    rec['geometry']['type'] = 'Polygon'\n",
    "\n",
    "                # if any point in polygon lies in bBox, add the poylgon to the output\n",
    "                if polygon_intersects_box(rec['geometry'], boundingBox):\n",
    "                    #newProps = {'id': idCnt}\n",
    "                    newProps = {}\n",
    "                    for key,val in propMap.items():\n",
    "                        newProps[val] = rec['properties'][key]\n",
    "                    rec['properties'] = newProps\n",
    "                    recList.append(newProps)\n",
    "                    sink.write(rec)\n",
    "                    idCnt += 1\n",
    "\n",
    "    return recList\n",
    "\n",
    "\n",
    "# true if any point of geomElem's polygon is inside the bounding box (intersect, not necessarily fully within/contained)\n",
    "def polygon_intersects_box(geomElem, bBox):\n",
    "    # if no box, don't filter\n",
    "    if bBox is None:\n",
    "        return True\n",
    "\n",
    "    for geomPolygon in geomElem['coordinates']:\n",
    "        polygonCoords = np.array(geomPolygon)\n",
    "        if any( map(lambda x: (bBox[0][0] < x[0] < bBox[1][0] and x[1] < bBox[1][1] < bBox[0][1]), polygonCoords) ):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "shapeFile = '../data/shapefiles-us_zips/cb_2017_us_zcta510_500k'\n",
    "filterFunction = lambda x: True\n",
    "propertyMap = {'ZCTA5CE10':'zip'}\n",
    "boundingBox = [[-90, 42.5], [-89, 43.5]]\n",
    "boundingBox = None\n",
    "recList = translate_shapefile_bounding_box(shapeFile, filterFunction , propertyMap, boundingBox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  AL\n",
      "1 :  DE\n",
      "2 :  WI\n",
      "3 :  AK\n",
      "4 :  IL\n",
      "5 :  IA\n",
      "6 :  UT\n",
      "7 :  MA\n",
      "8 :  SC\n",
      "9 :  TX\n",
      "10 :  RI\n",
      "11 :  PA\n",
      "12 :  OR\n",
      "13 :  GA\n",
      "14 :  SD\n",
      "15 :  NH\n",
      "16 :  OH\n",
      "17 :  NJ\n",
      "18 :  WA\n",
      "19 :  ME\n",
      "20 :  NY\n",
      "21 :  CO\n",
      "22 :  NE\n",
      "23 :  VT\n",
      "24 :  CA\n",
      "25 :  WY\n",
      "26 :  FL\n",
      "27 :  MN\n",
      "28 :  MS\n",
      "29 :  ID\n",
      "30 :  AR\n",
      "31 :  MI\n",
      "32 :  WV\n",
      "33 :  IN\n",
      "34 :  MT\n",
      "35 :  LA\n",
      "36 :  NC\n",
      "37 :  NM\n",
      "38 :  KY\n",
      "39 :  DC\n",
      "40 :  OK\n",
      "41 :  MO\n",
      "42 :  AZ\n",
      "43 :  ND\n",
      "44 :  TN\n",
      "45 :  HI\n",
      "46 :  PR\n",
      "47 :  KS\n",
      "48 :  MD\n",
      "49 :  CT\n",
      "50 :  NV\n",
      "51 :  VA\n"
     ]
    }
   ],
   "source": [
    "def get_state_zip_df():\n",
    "    saveFile = '../data/shapefiles-us_zips/zip_state_map.csv'\n",
    "    # try to read read pre-downloaded and massaged file (if run/'cached' before), else download and save\n",
    "    # feels sloppy\n",
    "    try:\n",
    "        stateZipDf = pd.read_csv(saveFile, dtype=str)\n",
    "    except FileNotFoundError:\n",
    "        zipCol = 'ZCTA5'\n",
    "        stateCol = 'STUSAB'\n",
    "        stateIdCol = 'STATE'\n",
    "        readType = {zipCol: str, stateCol: str}\n",
    "\n",
    "        zipSourceURL = 'https://www2.census.gov/geo/docs/maps-data/data/rel/zcta_place_rel_10.txt'\n",
    "        zipInfoDf = pd.read_csv(zipSourceURL, usecols=[zipCol, stateIdCol], dtype=readType)\n",
    "        zipInfoDf.drop_duplicates(inplace=True)  # not sure what this data means, but there are several rows per zip\n",
    "\n",
    "        stateSourceURL = 'https://www2.census.gov/geo/docs/reference/state.txt'\n",
    "        stateInfoDf = pd.read_csv(stateSourceURL, sep='|')\n",
    "\n",
    "        # pandas JOIN on state(FIPS ID)\n",
    "        stateZipDf = pd.merge(zipInfoDf, stateInfoDf, left_on=stateIdCol, right_on=stateIdCol)\n",
    "        stateZipDf = stateZipDf[[zipCol, stateCol]]\n",
    "        #stateZipDf[zipCol] = stateZipDf[zipCol].apply(lambda x: str(x).rjust(5, '0'))  # convert zip from int to 5 char str #passing dtype=str on read already accomplishes this\n",
    "\n",
    "        stateZipDf.to_csv(saveFile, index=False)  # save, don't print index column\n",
    "\n",
    "    return stateZipDf\n",
    "\n",
    "# pass the stateZipDf from get_state_zip_df()\n",
    "# zip2StateDict[zipCode] = [state_zip_code_is_in, maybe_more_than_1_state]\n",
    "# state2ZipDict[state][zipCode]=''\n",
    "def gen_state_zip_dict(stateZipDf):\n",
    "    zipCol = 'ZCTA5'\n",
    "    stateCol = 'STUSAB'\n",
    "\n",
    "    zip2StateDict = {}\n",
    "    state2ZipDict = {}\n",
    "    for row in stateZipDf.iterrows():\n",
    "        zipCode = row[1][zipCol]\n",
    "        stateStr = row[1][stateCol]\n",
    "\n",
    "        if zipCode in zip2StateDict:\n",
    "            # print(zipCode, stateStr)  # zip codes in more than 1 state. interesting\n",
    "            zip2StateDict[zipCode].append(stateStr)\n",
    "        else:\n",
    "            zip2StateDict[zipCode] = [stateStr]\n",
    "\n",
    "        if stateStr in state2ZipDict:\n",
    "            state2ZipDict[stateStr][zipCode] = True\n",
    "        else:\n",
    "            state2ZipDict[stateStr] = {zipCode: True}\n",
    "\n",
    "    return zip2StateDict, state2ZipDict\n",
    "\n",
    "# the quickest, dirtiest, dumbest way to make a separate zip file for each state:\n",
    "#   re-read the shape file once for each state and only print the zips that are in the state\n",
    "def create_state_zip_bounds_files(shapeFile):\n",
    "    zipDf = get_state_zip_df()\n",
    "    zipDict, stateDict = gen_state_zip_dict(zipDf)\n",
    "\n",
    "    stateCnt = 0\n",
    "    for state in stateDict.keys():\n",
    "        print(stateCnt, ': ', state)\n",
    "        stateCnt += 1\n",
    "        sinkFile = shapeFile+'_'+state+'.json'\n",
    "        # gdal doesn't know how to overwrite a file\n",
    "        if os.path.isfile(sinkFile):\n",
    "            os.remove(sinkFile)\n",
    "\n",
    "        with fiona.open(shapeFile+'.shp', 'r') as src:\n",
    "            meta = src.meta\n",
    "            meta['schema']['properties'] = {'zip': 'str'}\n",
    "            meta['driver'] = 'GeoJSON'\n",
    "            with fiona.open(sinkFile, 'w', **meta) as sink:\n",
    "                for rec in src:\n",
    "                    #only include zips in this state\n",
    "                    if rec['properties']['ZCTA5CE10'] not in stateDict[state]:\n",
    "                        continue\n",
    "\n",
    "                    # I don't like displaying all the quirks of zip boundaries (and may be more costly to render), but this block isn't necessary\n",
    "                    # not polygon means the multi-level/nested polygon thing. This removes those complicated compound shapes\n",
    "                    if rec['geometry']['type'] != 'Polygon':\n",
    "                        # simplify multipolygon to polygon:\n",
    "                        # if polygon has negative space, the first element is the outer bound, skip other/interior pieces\n",
    "                        # if polygon consists of multiple, separate pieces (like islands) we include all of those\n",
    "                        newCoords = [coordSet[0] for coordSet in rec['geometry']['coordinates']]\n",
    "                        rec['geometry']['coordinates'] = newCoords\n",
    "                        rec['geometry']['type'] = 'Polygon'\n",
    "\n",
    "                    rec['properties'] = {'zip': rec['properties']['ZCTA5CE10']}\n",
    "                    sink.write(rec)\n",
    "\n",
    "    return\n",
    "\n",
    "create_state_zip_bounds_files('../data/shapefiles-us_zips/cb_2017_us_zcta510_500k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outFile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0d227a65665d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutFile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'outFile' is not defined"
     ]
    }
   ],
   "source": [
    "outFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#map zip codes to states and vice-versa\n",
    "zipCol = 'ZCTA5'\n",
    "stateCol = 'STUSAB'\n",
    "readType = {zipCol:str, stateCol:str}\n",
    "\n",
    "zipSourceURL = 'https://www2.census.gov/geo/docs/maps-data/data/rel/zcta_place_rel_10.txt'\n",
    "zipStuff = pd.read_csv(zipSourceURL, usecols=['ZCTA5', 'STATE'], dtype=readType)\n",
    "zipStuff.drop_duplicates(inplace=True)\n",
    "\n",
    "stateSourceURL = 'https://www2.census.gov/geo/docs/reference/state.txt'\n",
    "stateStuff = pd.read_csv(stateSourceURL, sep='|')\n",
    "\n",
    "mergeStuff = pd.merge(zipStuff, stateStuff, left_on='STATE', right_on='STATE')\n",
    "mergeStuff = mergeStuff[[zipCol, stateCol]]\n",
    "#mergeStuff[zipCol] = mergeStuff[zipCol].apply(lambda x: str(x).rjust(5,'0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip2State = {}\n",
    "state2Zip = {}\n",
    "\n",
    "for row in zipStuff.iterrows():\n",
    "    vals = row[1]\n",
    "    zipCode = str(vals[zipCol]).rjust(5,'0')\n",
    "    stateStr = vals[stateCol]\n",
    "    \n",
    "    if zipCode in zip2State:\n",
    "        print(zipCode, stateStr)  #zip codes in more than1 state. neat\n",
    "        zip2State[zipCode].append(stateStr)\n",
    "    else:\n",
    "        zip2State[zipCode] = [stateStr]\n",
    "    \n",
    "    if stateStr in state2Zip:\n",
    "        state2Zip[stateStr][zipCode] = True\n",
    "    else:\n",
    "        state2Zip[stateStr] = {zipCode: True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#another data set to map zips to states. it's less good, prefer census bureau data\n",
    "\n",
    "#this is some income tax dataset or something, but it has state and zip - i wanna make a map/dict of zip->state\n",
    "fileDir = 'C:/Users/m/Downloads/'\n",
    "fileName = '16zpallagi.csv'\n",
    "columnKeys = ['STATEFIPS', 'STATE', 'zipcode', 'agi_stub']\n",
    "\n",
    "zipStuff = pd.read_csv(fileDir+fileName)\n",
    "if columnKeys:\n",
    "    zipStuff = zipStuff[columnKeys]\n",
    "\n",
    "#this agi_stub (adjusted gross income?) thing is like some subset of the population, maybe like tax bracket, there are 6 per zip \n",
    "zipStuff = zipStuff[(zipStuff['zipcode']!=0) & (zipStuff['agi_stub']==1) & (zipStuff['zipcode']!=99999)]\n",
    "\n",
    "zipCol = 'zipcode'\n",
    "stateCol = 'STATE'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
